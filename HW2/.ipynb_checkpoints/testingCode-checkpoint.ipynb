{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "169dbb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sneha Dubey (W1618643)\n",
    "# Dr. Chen\n",
    "# CSCI 184\n",
    "# 04/22/2024\n",
    "# Homework 2 Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6784bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import graphviz\n",
    "import pprint\n",
    "import itertools \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea324efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE TO IMPLEMENT\n",
    "\n",
    "def partition(x):\n",
    "    partitions = {}\n",
    "    uniqueX = np.unique(x)\n",
    "    for ux in uniqueX:\n",
    "        partitions[ux] = np.where(x == ux)[0]\n",
    "    return partitions\n",
    "\n",
    "\n",
    "\n",
    "def entropy(y):\n",
    "    ENT = 0\n",
    "    labels = np.unique(y)\n",
    "    for l in labels:\n",
    "        targetLabelCount = 0\n",
    "        for index in range(0, len(y)):\n",
    "            if y[index] == l:\n",
    "                targetLabelCount += 1\n",
    "        p = targetLabelCount / len(y)\n",
    "        ENT -= p*np.log2(p)\n",
    "    return ENT\n",
    "\n",
    "\n",
    "\n",
    "def information_gain(x, y):\n",
    "    pENT = entropy(y)\n",
    "    partitions = partition(x)\n",
    "    wcENT = 0\n",
    "    \n",
    "    for part in partitions.values():\n",
    "        cENT = entropy(y[part])\n",
    "        partW = len(part)/len(y)\n",
    "        wcENT += partW*cENT\n",
    "    IG = pENT - wcENT\n",
    "    return IG\n",
    "\n",
    "\n",
    "\n",
    "def id3(x, y, attribute_value_pairs=None, depth=0, max_depth=5):\n",
    "    # first stopping condition\n",
    "    if len(np.unique(y)) == 1:\n",
    "        return np.unique(y)[0]\n",
    "    \n",
    "    # second stopping condition\n",
    "    if attribute_value_pairs == None:\n",
    "        mostCommonLabel = 0\n",
    "        mclCount = 0\n",
    "        for label in np.unique(y):\n",
    "            currLabelCount = 0\n",
    "            for obj in y:\n",
    "                if obj == label:\n",
    "                    currLabelCount += 1\n",
    "            if currLabelCount > mclCount:\n",
    "                mostCommonLabel = label\n",
    "                mclCount = currLabelCount\n",
    "        return mostCommonLabel\n",
    "    \n",
    "    # third stopping condition\n",
    "    if depth == max_depth:\n",
    "        mostCommonLabel = 0\n",
    "        mclCount = 0\n",
    "        for label in np.unique(y):\n",
    "            currLabelCount = 0\n",
    "            for obj in y:\n",
    "                if obj == label:\n",
    "                    currLabelCount += 1\n",
    "            if currLabelCount > mclCount:\n",
    "                mostCommonLabel = label\n",
    "                mclCount = currLabelCount\n",
    "        return mostCommonLabel\n",
    "    \n",
    "    # selecting the next-best attribute-value pair using information_gain()\n",
    "    bestAVP = ()\n",
    "    maxIG = 0\n",
    "    for avp in attribute_value_pairs:\n",
    "        currIG = information_gain(x[:, avp[0]], y)\n",
    "        if currIG > maxIG:\n",
    "            bestAVP = avp\n",
    "            maxIG = currIG\n",
    "    \n",
    "    # getting all remaining attribute-value pairs\n",
    "    otherAVP = []\n",
    "    for attribute, value in attribute_value_pairs:\n",
    "        if attribute != bestAVP[0]:\n",
    "            otherAVP.append((attribute, value))\n",
    "\n",
    "    # partitioning on bestAVP\n",
    "    partitions = partition(x[:, bestAVP[0]])\n",
    "    \n",
    "    # recursive call to ID3\n",
    "    tree = {}\n",
    "    for value, indices in partitions.items():\n",
    "        if len(indices) == 0:\n",
    "            mostCommonLabel = 0\n",
    "            mclCount = 0\n",
    "            for label in np.unique(y):\n",
    "                currLabelCount = 0\n",
    "                for obj in y:\n",
    "                    if obj == label:\n",
    "                        currLabelCount += 1\n",
    "                if currLabelCount > mclCount:\n",
    "                    mostCommonLabel = label\n",
    "                    mclCount = currLabelCount\n",
    "            tree[(bestAVP[0], value, True)] = mostCommonLabel\n",
    "        else:\n",
    "            tree[(bestAVP[0], value, True)] = id3(x[indices], y[indices], otherAVP, depth + 1, max_depth)\n",
    "    return tree\n",
    "\n",
    "\n",
    "\n",
    "def predict_example(x, tree):\n",
    "    print(tree)\n",
    "    if type(tree) == int:\n",
    "        print('PREDICTED ', tree)\n",
    "        return tree\n",
    "    if type(tree) == dict:\n",
    "        print(tree.keys())\n",
    "        attribute = list(tree.keys())[0][0]\n",
    "        print(attribute)\n",
    "        value = list(tree.keys())[0][1]\n",
    "        print(value)\n",
    "        if x[attribute] == value:\n",
    "            print('PREDICTED to true')\n",
    "            return predict_example(x, tree[(attribute, value, True)])\n",
    "        else:\n",
    "            return predict_example(x, tree[(attribute, value, False)])\n",
    "\n",
    "\n",
    "\n",
    "def compute_error(y_true, y_pred):\n",
    "    incorrect = 0\n",
    "    n = len(y_pred)\n",
    "    for (true, pred) in zip(y_true, y_pred):\n",
    "        if true != pred:\n",
    "            incorrect += 1\n",
    "    error = (1/n)*incorrect\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bb6d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THESE\n",
    "\n",
    "def pretty_print(tree, depth=0):\n",
    "    \"\"\"\n",
    "    Pretty prints the decision tree to the console. Use print(tree) to print the raw nested dictionary representation\n",
    "    DO NOT MODIFY THIS FUNCTION!\n",
    "    \"\"\"\n",
    "    if depth == 0:\n",
    "        print('TREE')\n",
    "\n",
    "    for index, split_criterion in enumerate(tree):\n",
    "        sub_trees = tree[split_criterion]\n",
    "\n",
    "        # Print the current node: split criterion\n",
    "        print('|\\t' * depth, end='')\n",
    "        print('+-- [SPLIT: x{0} = {1} {2}]'.format(split_criterion[0], split_criterion[1], split_criterion[2]))\n",
    "\n",
    "        # Print the children\n",
    "        if type(sub_trees) is dict:\n",
    "            pretty_print(sub_trees, depth + 1)\n",
    "        else:\n",
    "            print('|\\t' * (depth + 1), end='')\n",
    "            print('+-- [LABEL = {0}]'.format(sub_trees))\n",
    "\n",
    "            \n",
    "\n",
    "def render_dot_file(dot_string, save_file, image_format='png'):\n",
    "    \"\"\"\n",
    "    Uses GraphViz to render a dot file. The dot file can be generated using\n",
    "        * sklearn.tree.export_graphviz()' for decision trees produced by scikit-learn\n",
    "        * to_graphviz() (function is in this file) for decision trees produced by  your code.\n",
    "    Modify Path to your GraphViz executable if needed. DO NOT MODIFY OTHER PART OF THIS FUNCTION!\n",
    "    \"\"\"\n",
    "    if type(dot_string).__name__ != 'str':\n",
    "        raise TypeError('visualize() requires a string representation of a decision tree.\\nUse tree.export_graphviz()'\n",
    "                        'for decision trees produced by scikit-learn and to_graphviz() for decision trees produced by'\n",
    "                        'your code.\\n')\n",
    "\n",
    "    # Set path to your GraphViz executable here\n",
    "    os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "    graph = graphviz.Source(dot_string)\n",
    "    graph.format = image_format\n",
    "    graph.render(save_file, view=True)\n",
    "\n",
    "\n",
    "    \n",
    "def to_graphviz(tree, dot_string='', uid=-1, depth=0):\n",
    "    \"\"\"\n",
    "    Converts a tree to DOT format for use with visualize/GraphViz\n",
    "    DO NOT MODIFY THIS FUNCTION!\n",
    "    \"\"\"\n",
    "\n",
    "    uid += 1       # Running index of node ids across recursion\n",
    "    node_id = uid  # Node id of this node\n",
    "\n",
    "    if depth == 0:\n",
    "        dot_string += 'digraph TREE {\\n'\n",
    "\n",
    "    for split_criterion in tree:\n",
    "        sub_trees = tree[split_criterion]\n",
    "        attribute_index = split_criterion[0]\n",
    "        attribute_value = split_criterion[1]\n",
    "        split_decision = split_criterion[2]\n",
    "\n",
    "        if not split_decision:\n",
    "            # Alphabetically, False comes first\n",
    "            dot_string += '    node{0} [label=\"x{1} = {2}?\"];\\n'.format(node_id, attribute_index, attribute_value)\n",
    "\n",
    "        if type(sub_trees) is dict:\n",
    "            if not split_decision:\n",
    "                dot_string, right_child, uid = to_graphviz(sub_trees, dot_string=dot_string, uid=uid, depth=depth + 1)\n",
    "                dot_string += '    node{0} -> node{1} [label=\"False\"];\\n'.format(node_id, right_child)\n",
    "            else:\n",
    "                dot_string, left_child, uid = to_graphviz(sub_trees, dot_string=dot_string, uid=uid, depth=depth + 1)\n",
    "                dot_string += '    node{0} -> node{1} [label=\"True\"];\\n'.format(node_id, left_child)\n",
    "\n",
    "        else:\n",
    "            uid += 1\n",
    "            dot_string += '    node{0} [label=\"y = {1}\"];\\n'.format(uid, sub_trees)\n",
    "            if not split_decision:\n",
    "                dot_string += '    node{0} -> node{1} [label=\"False\"];\\n'.format(node_id, uid)\n",
    "            else:\n",
    "                dot_string += '    node{0} -> node{1} [label=\"True\"];\\n'.format(node_id, uid)\n",
    "\n",
    "    if depth == 0:\n",
    "        dot_string += '}\\n'\n",
    "        return dot_string\n",
    "    else:\n",
    "        return dot_string, node_id, uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef8cd8b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(4, 1, True): 1,\n",
      " (4, 2, True): {(3, 1, True): {(2, 1, True): 1, (2, 2, True): 0},\n",
      "                (3, 2, True): {(1, 1, True): 0,\n",
      "                               (1, 2, True): 1,\n",
      "                               (1, 3, True): 0},\n",
      "                (3, 3, True): {(2, 1, True): 1, (2, 2, True): 0}},\n",
      " (4, 3, True): {(5, 1, True): {(3, 1, True): 0,\n",
      "                               (3, 2, True): 0,\n",
      "                               (3, 3, True): 0},\n",
      "                (5, 2, True): {(2, 1, True): 1, (2, 2, True): 0}},\n",
      " (4, 4, True): {(3, 1, True): {(2, 1, True): 0, (2, 2, True): 1},\n",
      "                (3, 2, True): {(1, 1, True): 0,\n",
      "                               (1, 2, True): 0,\n",
      "                               (1, 3, True): 0},\n",
      "                (3, 3, True): {(1, 1, True): 0,\n",
      "                               (1, 2, True): 0,\n",
      "                               (1, 3, True): 0}}}\n",
      "TREE\n",
      "+-- [SPLIT: x4 = 1 True]\n",
      "|\t+-- [LABEL = 1]\n",
      "+-- [SPLIT: x4 = 2 True]\n",
      "|\t+-- [SPLIT: x3 = 1 True]\n",
      "|\t|\t+-- [SPLIT: x2 = 1 True]\n",
      "|\t|\t|\t+-- [LABEL = 1]\n",
      "|\t|\t+-- [SPLIT: x2 = 2 True]\n",
      "|\t|\t|\t+-- [LABEL = 0]\n",
      "|\t+-- [SPLIT: x3 = 2 True]\n",
      "|\t|\t+-- [SPLIT: x1 = 1 True]\n",
      "|\t|\t|\t+-- [LABEL = 0]\n",
      "|\t|\t+-- [SPLIT: x1 = 2 True]\n",
      "|\t|\t|\t+-- [LABEL = 1]\n",
      "|\t|\t+-- [SPLIT: x1 = 3 True]\n",
      "|\t|\t|\t+-- [LABEL = 0]\n",
      "|\t+-- [SPLIT: x3 = 3 True]\n",
      "|\t|\t+-- [SPLIT: x2 = 1 True]\n",
      "|\t|\t|\t+-- [LABEL = 1]\n",
      "|\t|\t+-- [SPLIT: x2 = 2 True]\n",
      "|\t|\t|\t+-- [LABEL = 0]\n",
      "+-- [SPLIT: x4 = 3 True]\n",
      "|\t+-- [SPLIT: x5 = 1 True]\n",
      "|\t|\t+-- [SPLIT: x3 = 1 True]\n",
      "|\t|\t|\t+-- [LABEL = 0]\n",
      "|\t|\t+-- [SPLIT: x3 = 2 True]\n",
      "|\t|\t|\t+-- [LABEL = 0]\n",
      "|\t|\t+-- [SPLIT: x3 = 3 True]\n",
      "|\t|\t|\t+-- [LABEL = 0]\n",
      "|\t+-- [SPLIT: x5 = 2 True]\n",
      "|\t|\t+-- [SPLIT: x2 = 1 True]\n",
      "|\t|\t|\t+-- [LABEL = 1]\n",
      "|\t|\t+-- [SPLIT: x2 = 2 True]\n",
      "|\t|\t|\t+-- [LABEL = 0]\n",
      "+-- [SPLIT: x4 = 4 True]\n",
      "|\t+-- [SPLIT: x3 = 1 True]\n",
      "|\t|\t+-- [SPLIT: x2 = 1 True]\n",
      "|\t|\t|\t+-- [LABEL = 0]\n",
      "|\t|\t+-- [SPLIT: x2 = 2 True]\n",
      "|\t|\t|\t+-- [LABEL = 1]\n",
      "|\t+-- [SPLIT: x3 = 2 True]\n",
      "|\t|\t+-- [SPLIT: x1 = 1 True]\n",
      "|\t|\t|\t+-- [LABEL = 0]\n",
      "|\t|\t+-- [SPLIT: x1 = 2 True]\n",
      "|\t|\t|\t+-- [LABEL = 0]\n",
      "|\t|\t+-- [SPLIT: x1 = 3 True]\n",
      "|\t|\t|\t+-- [LABEL = 0]\n",
      "|\t+-- [SPLIT: x3 = 3 True]\n",
      "|\t|\t+-- [SPLIT: x1 = 1 True]\n",
      "|\t|\t|\t+-- [LABEL = 0]\n",
      "|\t|\t+-- [SPLIT: x1 = 2 True]\n",
      "|\t|\t|\t+-- [LABEL = 0]\n",
      "|\t|\t+-- [SPLIT: x1 = 3 True]\n",
      "|\t|\t|\t+-- [LABEL = 0]\n",
      "{(4, 1, True): 1, (4, 2, True): {(3, 1, True): {(2, 1, True): 1, (2, 2, True): 0}, (3, 2, True): {(1, 1, True): 0, (1, 2, True): 1, (1, 3, True): 0}, (3, 3, True): {(2, 1, True): 1, (2, 2, True): 0}}, (4, 3, True): {(5, 1, True): {(3, 1, True): 0, (3, 2, True): 0, (3, 3, True): 0}, (5, 2, True): {(2, 1, True): 1, (2, 2, True): 0}}, (4, 4, True): {(3, 1, True): {(2, 1, True): 0, (2, 2, True): 1}, (3, 2, True): {(1, 1, True): 0, (1, 2, True): 0, (1, 3, True): 0}, (3, 3, True): {(1, 1, True): 0, (1, 2, True): 0, (1, 3, True): 0}}}\n",
      "dict_keys([(4, 1, True), (4, 2, True), (4, 3, True), (4, 4, True)])\n",
      "4\n",
      "1\n",
      "PREDICTED to true\n",
      "1\n",
      "{(4, 1, True): 1, (4, 2, True): {(3, 1, True): {(2, 1, True): 1, (2, 2, True): 0}, (3, 2, True): {(1, 1, True): 0, (1, 2, True): 1, (1, 3, True): 0}, (3, 3, True): {(2, 1, True): 1, (2, 2, True): 0}}, (4, 3, True): {(5, 1, True): {(3, 1, True): 0, (3, 2, True): 0, (3, 3, True): 0}, (5, 2, True): {(2, 1, True): 1, (2, 2, True): 0}}, (4, 4, True): {(3, 1, True): {(2, 1, True): 0, (2, 2, True): 1}, (3, 2, True): {(1, 1, True): 0, (1, 2, True): 0, (1, 3, True): 0}, (3, 3, True): {(1, 1, True): 0, (1, 2, True): 0, (1, 3, True): 0}}}\n",
      "dict_keys([(4, 1, True), (4, 2, True), (4, 3, True), (4, 4, True)])\n",
      "4\n",
      "1\n",
      "PREDICTED to true\n",
      "1\n",
      "{(4, 1, True): 1, (4, 2, True): {(3, 1, True): {(2, 1, True): 1, (2, 2, True): 0}, (3, 2, True): {(1, 1, True): 0, (1, 2, True): 1, (1, 3, True): 0}, (3, 3, True): {(2, 1, True): 1, (2, 2, True): 0}}, (4, 3, True): {(5, 1, True): {(3, 1, True): 0, (3, 2, True): 0, (3, 3, True): 0}, (5, 2, True): {(2, 1, True): 1, (2, 2, True): 0}}, (4, 4, True): {(3, 1, True): {(2, 1, True): 0, (2, 2, True): 1}, (3, 2, True): {(1, 1, True): 0, (1, 2, True): 0, (1, 3, True): 0}, (3, 3, True): {(1, 1, True): 0, (1, 2, True): 0, (1, 3, True): 0}}}\n",
      "dict_keys([(4, 1, True), (4, 2, True), (4, 3, True), (4, 4, True)])\n",
      "4\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "(4, 1, False)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m render_dot_file(dot_str, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./my_learned_tree\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Compute the test error\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m [predict_example(x, decision_tree) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m Xtst]\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(ytst)\n",
      "Cell \u001b[0;32mIn[5], line 37\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     34\u001b[0m render_dot_file(dot_str, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./my_learned_tree\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Compute the test error\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m [\u001b[43mpredict_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecision_tree\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m Xtst]\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(ytst)\n",
      "Cell \u001b[0;32mIn[3], line 127\u001b[0m, in \u001b[0;36mpredict_example\u001b[0;34m(x, tree)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict_example(x, tree[(attribute, value, \u001b[38;5;28;01mTrue\u001b[39;00m)])\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict_example(x, \u001b[43mtree\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattribute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mKeyError\u001b[0m: (4, 1, False)"
     ]
    }
   ],
   "source": [
    "# MAIN (MAY MODIFY IF NEEDED)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #You may modify the following parts as needed\n",
    "    \n",
    "    # Load the training data\n",
    "    M = np.genfromtxt('monks_data/monks-1.train', missing_values=0, skip_header=0, delimiter=',', dtype=int)\n",
    "    ytrn = M[:, 0]\n",
    "    Xtrn = M[:, 1:]\n",
    "\n",
    "    # Load the test data\n",
    "    M = np.genfromtxt('monks_data/monks-1.test', missing_values=0, skip_header=0, delimiter=',', dtype=int)\n",
    "    ytst = M[:, 0]\n",
    "    Xtst = M[:, 1:]\n",
    "\n",
    "    # Get attribute_value_pair for the data\n",
    "    AVP = []\n",
    "    for obj in M:\n",
    "        for i in range(1, 6):\n",
    "            if (i, obj[i]) not in AVP:\n",
    "                AVP.append((i, obj[i]))\n",
    "    \n",
    "    # Learn a decision tree of depth 3\n",
    "    decision_tree = id3(Xtrn, ytrn, AVP, 0, 3)\n",
    "    \n",
    "    pprint.pprint(decision_tree)\n",
    "\n",
    "    # Pretty print it to console\n",
    "    pretty_print(decision_tree)\n",
    "    \n",
    "    # Visualize the tree and save it as a PNG image\n",
    "    dot_str = to_graphviz(decision_tree)\n",
    "    render_dot_file(dot_str, './my_learned_tree')\n",
    "\n",
    "    # Compute the test error\n",
    "    y_pred = [predict_example(x, decision_tree) for x in Xtst]\n",
    "    print(y_pred)\n",
    "    print(ytst)\n",
    "    tst_err = compute_error(ytst, y_pred)\n",
    "\n",
    "    print('Test Error = {0:4.2f}%.'.format(tst_err * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b654bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
