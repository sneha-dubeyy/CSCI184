{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd2044fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TREE\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.int64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 286\u001b[0m\n\u001b[1;32m    283\u001b[0m decision_tree \u001b[38;5;241m=\u001b[39m id3(Xtrn, ytrn, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# Pretty print it to console\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m \u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecision_tree\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# Visualize the tree and save it as a PNG image\u001b[39;00m\n\u001b[1;32m    289\u001b[0m dot_str \u001b[38;5;241m=\u001b[39m to_graphviz(decision_tree)\n",
      "Cell \u001b[0;32mIn[2], line 189\u001b[0m, in \u001b[0;36mpretty_print\u001b[0;34m(tree, depth)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m depth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTREE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, split_criterion \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    190\u001b[0m     sub_trees \u001b[38;5;241m=\u001b[39m tree[split_criterion]\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# Print the current node: split criterion\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.int64' object is not iterable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def partition(x):\n",
    "    partitions = {}\n",
    "    uniqueX = np.unique(x)\n",
    "    for ux in uniqueX:\n",
    "        partitions[ux] = np.where(x == ux)[0]\n",
    "    return partitions\n",
    "\n",
    "def entropy(y):\n",
    "    ENT = 0\n",
    "    labels = np.unique(y)\n",
    "    for l in labels:\n",
    "        targetLabelCount = 0\n",
    "        for index in range(0, len(y)):\n",
    "            if y[index] == l:\n",
    "                targetLabelCount += 1\n",
    "        p = targetLabelCount / len(y)\n",
    "        ENT += p*np.log2(p)\n",
    "    return ENT\n",
    "\n",
    "def information_gain(x, y):\n",
    "    pENT = entropy(y)\n",
    "    partitions = partition(x)\n",
    "    wcENT = 0\n",
    "    \n",
    "    for part in partitions.values():\n",
    "        cENT = entropy(y[part])\n",
    "        partW = len(part)/len(y)\n",
    "        wcENT += partW*cENT\n",
    "    IG = pENT - wcENT\n",
    "    return IG\n",
    "\n",
    "def id3(x, y, attribute_value_pairs=None, depth=0, max_depth=5):\n",
    "    # first stopping condition\n",
    "    if len(np.unique(y)) == 1:\n",
    "        return np.unique(y)[0]\n",
    "    \n",
    "    # second stopping condition\n",
    "    if attribute_value_pairs == None:\n",
    "        mostCommonLabel = 0\n",
    "        mclCount = 0\n",
    "        for label in np.unique(y):\n",
    "            currLabelCount = 0\n",
    "            for obj in y:\n",
    "                if obj == label:\n",
    "                    currLabelCount += 1\n",
    "            if currLabelCount > mclCount:\n",
    "                mostCommonLabel = label\n",
    "                mclCount = currLabelCount\n",
    "        return mostCommonLabel\n",
    "    \n",
    "    # third stopping condition\n",
    "    if depth == max_depth:\n",
    "        mostCommonLabel = 0\n",
    "        mclCount = 0\n",
    "        for label in np.unique(y):\n",
    "            currLabelCount = 0\n",
    "            for obj in y:\n",
    "                if obj == label:\n",
    "                    currLabelCount += 1\n",
    "            if currLabelCount > mclCount:\n",
    "                mostCommonLabel = label\n",
    "                mclCount = currLabelCount\n",
    "        return mostCommonLabel\n",
    "    \n",
    "    # selecting the next-best attribute-value pair using information_gain()\n",
    "    bestAVP = []\n",
    "    maxIG = 0\n",
    "    for avp in attribute_value_pairs:\n",
    "        currIG = information_gain(x[:, avp[0]], y)\n",
    "        if currIG > maxIG:\n",
    "            bestAVP = avp\n",
    "            maxIG = currIG\n",
    "    \n",
    "    # getting all remaining attribute-value pairs\n",
    "    otherAVP = []\n",
    "    for attribute, value in attribute_value_pairs:\n",
    "        if attribute != bestAVP[0]:\n",
    "            otherAVP += (attribute, value)\n",
    "   \n",
    "    # partitioning on bestAVP\n",
    "    partitions = partition(x[:, bestAVP[0]])\n",
    "    \n",
    "    # recursive call to ID3\n",
    "    tree = {}\n",
    "    for value, indices in partitions.items():\n",
    "        if len(indices) == 0:\n",
    "            mostCommonLabel = 0\n",
    "            mclCount = 0\n",
    "            for label in np.unique(y):\n",
    "                currLabelCount = 0\n",
    "                for obj in y:\n",
    "                    if obj == label:\n",
    "                        currLabelCount += 1\n",
    "                if currLabelCount > mclCount:\n",
    "                    mostCommonLabel = label\n",
    "                    mclCount = currLabelCount\n",
    "            tree[(bestAVP[0], value, True)] = mostCommonLabel\n",
    "        else:\n",
    "            tree[(bestAVP[0], value, True)] = id3(x[indices], y[indices], otherAVP, depth + 1, max_depth)\n",
    "            \n",
    "    return tree\n",
    "\n",
    "\n",
    "\n",
    "def predict_example(x, tree):\n",
    "    if type(tree) == int:\n",
    "        return tree\n",
    "    else:\n",
    "        attribute = list(tree.keys())[0][0]\n",
    "        value = list(tree.keys())[0][1]\n",
    "        if x[attribute] == value:\n",
    "            return predict_example(x, tree[(attribute, value, True)])\n",
    "        else:\n",
    "            return predict_example(x, tree[(attribute, value, False)])\n",
    "\n",
    "\n",
    "def compute_error(y_true, y_pred):\n",
    "    incorrect = 0\n",
    "    n = len(y_pred)\n",
    "    for true in y_true, pred in y_pred:\n",
    "        if true != pred:\n",
    "            incorrect += 1\n",
    "    error = (1/n)*incorrect\n",
    "    return error\n",
    "\n",
    "\n",
    "def pretty_print(tree, depth=0):\n",
    "    \"\"\"\n",
    "    Pretty prints the decision tree to the console. Use print(tree) to print the raw nested dictionary representation\n",
    "    DO NOT MODIFY THIS FUNCTION!\n",
    "    \"\"\"\n",
    "    if depth == 0:\n",
    "        print('TREE')\n",
    "\n",
    "    for index, split_criterion in enumerate(tree):\n",
    "        sub_trees = tree[split_criterion]\n",
    "\n",
    "        # Print the current node: split criterion\n",
    "        print('|\\t' * depth, end='')\n",
    "        print('+-- [SPLIT: x{0} = {1} {2}]'.format(split_criterion[0], split_criterion[1], split_criterion[2]))\n",
    "\n",
    "        # Print the children\n",
    "        if type(sub_trees) is dict:\n",
    "            pretty_print(sub_trees, depth + 1)\n",
    "        else:\n",
    "            print('|\\t' * (depth + 1), end='')\n",
    "            print('+-- [LABEL = {0}]'.format(sub_trees))\n",
    "\n",
    "\n",
    "def render_dot_file(dot_string, save_file, image_format='png'):\n",
    "    \"\"\"\n",
    "    Uses GraphViz to render a dot file. The dot file can be generated using\n",
    "        * sklearn.tree.export_graphviz()' for decision trees produced by scikit-learn\n",
    "        * to_graphviz() (function is in this file) for decision trees produced by  your code.\n",
    "    Modify Path to your GraphViz executable if needed. DO NOT MODIFY OTHER PART OF THIS FUNCTION!\n",
    "    \"\"\"\n",
    "    if type(dot_string).__name__ != 'str':\n",
    "        raise TypeError('visualize() requires a string representation of a decision tree.\\nUse tree.export_graphviz()'\n",
    "                        'for decision trees produced by scikit-learn and to_graphviz() for decision trees produced by'\n",
    "                        'your code.\\n')\n",
    "\n",
    "    # Set path to your GraphViz executable here\n",
    "    os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "    graph = graphviz.Source(dot_string)\n",
    "    graph.format = image_format\n",
    "    graph.render(save_file, view=True)\n",
    "\n",
    "\n",
    "def to_graphviz(tree, dot_string='', uid=-1, depth=0):\n",
    "    \"\"\"\n",
    "    Converts a tree to DOT format for use with visualize/GraphViz\n",
    "    DO NOT MODIFY THIS FUNCTION!\n",
    "    \"\"\"\n",
    "\n",
    "    uid += 1       # Running index of node ids across recursion\n",
    "    node_id = uid  # Node id of this node\n",
    "\n",
    "    if depth == 0:\n",
    "        dot_string += 'digraph TREE {\\n'\n",
    "\n",
    "    for split_criterion in tree:\n",
    "        sub_trees = tree[split_criterion]\n",
    "        attribute_index = split_criterion[0]\n",
    "        attribute_value = split_criterion[1]\n",
    "        split_decision = split_criterion[2]\n",
    "\n",
    "        if not split_decision:\n",
    "            # Alphabetically, False comes first\n",
    "            dot_string += '    node{0} [label=\"x{1} = {2}?\"];\\n'.format(node_id, attribute_index, attribute_value)\n",
    "\n",
    "        if type(sub_trees) is dict:\n",
    "            if not split_decision:\n",
    "                dot_string, right_child, uid = to_graphviz(sub_trees, dot_string=dot_string, uid=uid, depth=depth + 1)\n",
    "                dot_string += '    node{0} -> node{1} [label=\"False\"];\\n'.format(node_id, right_child)\n",
    "            else:\n",
    "                dot_string, left_child, uid = to_graphviz(sub_trees, dot_string=dot_string, uid=uid, depth=depth + 1)\n",
    "                dot_string += '    node{0} -> node{1} [label=\"True\"];\\n'.format(node_id, left_child)\n",
    "\n",
    "        else:\n",
    "            uid += 1\n",
    "            dot_string += '    node{0} [label=\"y = {1}\"];\\n'.format(uid, sub_trees)\n",
    "            if not split_decision:\n",
    "                dot_string += '    node{0} -> node{1} [label=\"False\"];\\n'.format(node_id, uid)\n",
    "            else:\n",
    "                dot_string += '    node{0} -> node{1} [label=\"True\"];\\n'.format(node_id, uid)\n",
    "\n",
    "    if depth == 0:\n",
    "        dot_string += '}\\n'\n",
    "        return dot_string\n",
    "    else:\n",
    "        return dot_string, node_id, uid\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #You may modify the following parts as needed\n",
    "    \n",
    "    # Load the training data\n",
    "    M = np.genfromtxt('monks_data/monks-1.train', missing_values=0, skip_header=0, delimiter=',', dtype=int)\n",
    "    ytrn = M[:, 0]\n",
    "    Xtrn = M[:, 1:]\n",
    "\n",
    "    # Load the test data\n",
    "    M = np.genfromtxt('monks_data/monks-1.test', missing_values=0, skip_header=0, delimiter=',', dtype=int)\n",
    "    ytst = M[:, 0]\n",
    "    Xtst = M[:, 1:]\n",
    "\n",
    "    # Learn a decision tree of depth 3\n",
    "    decision_tree = id3(Xtrn, ytrn, max_depth=3)\n",
    "\n",
    "    # Pretty print it to console\n",
    "    pretty_print(decision_tree)\n",
    "\n",
    "    # Visualize the tree and save it as a PNG image\n",
    "    dot_str = to_graphviz(decision_tree)\n",
    "    render_dot_file(dot_str, './my_learned_tree')\n",
    "\n",
    "    # Compute the test error\n",
    "    y_pred = [predict_example(x, decision_tree) for x in Xtst]\n",
    "    tst_err = compute_error(ytst, y_pred)\n",
    "\n",
    "    print('Test Error = {0:4.2f}%.'.format(tst_err * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e9090e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
